{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ðŸ“š AI Agent - Find Author Publications (with Open Access Info)\n",
        "!pip install requests transformers sentencepiece PyMuPDF tqdm --quiet\n",
        "!pip install requests pandas arxiv rapidfuzz --quiet\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "import arxiv\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "def norm(s):\n",
        "    if not s: return \"\"\n",
        "    return \" \".join(s.replace(\"\\n\",\" \").split()).strip().lower()\n",
        "\n",
        "def openalex_author_works(author_name, max_works=50):\n",
        "    base = \"https://api.openalex.org\"\n",
        "    # Step 1: find author ID\n",
        "    r = requests.get(f\"{base}/authors\", params={\"search\": author_name, \"per-page\": 10})\n",
        "    if r.status_code != 200: return []\n",
        "    items = r.json().get(\"results\", [])\n",
        "    if not items: return []\n",
        "    # pick best match\n",
        "    scores = [(fuzz.partial_ratio(author_name.lower(), a.get(\"display_name\",\"\").lower()), a) for a in items]\n",
        "    scores.sort(reverse=True, key=lambda x: x[0])\n",
        "    best_score, best_author = scores[0]\n",
        "    if best_score < 50: return []\n",
        "    author_id = best_author.get(\"id\").split('/')[-1]\n",
        "    # Step 2: fetch works\n",
        "    works = []\n",
        "    params = {\"filter\": f\"author.id:A{author_id}\", \"per-page\": 25, \"sort\": \"cited_by_count:desc\"}\n",
        "    r2 = requests.get(f\"{base}/works\", params=params)\n",
        "    if r2.status_code != 200: return []\n",
        "    docs = r2.json().get(\"results\", [])[:max_works]\n",
        "    for w in docs:\n",
        "        wf = w.get(\"type\", \"\")\n",
        "        if wf not in [\"article\", \"book\"]:\n",
        "            continue\n",
        "        oa_info = w.get(\"open_access\", {})\n",
        "        oa_status = oa_info.get(\"is_oa\", False)\n",
        "        pdf_url = w.get(\"open_access_pdf\", {}).get(\"url\")\n",
        "        works.append({\n",
        "            \"title\": w.get(\"display_name\"),\n",
        "            \"authors\": \", \".join([au.get(\"author\",{}).get(\"display_name\",\"\") for au in w.get(\"authorships\",[])]),\n",
        "            \"year\": w.get(\"publication_year\"),\n",
        "            \"work_type\": wf,\n",
        "            \"open_access\": oa_status,\n",
        "            \"pdf_url\": pdf_url,\n",
        "            \"url\": w.get(\"id\"),\n",
        "            \"source\": \"OpenAlex\",\n",
        "            \"doi\": w.get(\"doi\")\n",
        "        })\n",
        "    return works\n",
        "\n",
        "def crossref_author_works(author_name, max_results=50):\n",
        "    url = \"https://api.crossref.org/works\"\n",
        "    params = {\"query.author\": author_name, \"rows\": max_results}\n",
        "    r = requests.get(url, params=params, headers={\"User-Agent\":\"research-agent/0.1\"})\n",
        "    if r.status_code != 200: return []\n",
        "    items = r.json().get(\"message\", {}).get(\"items\", [])\n",
        "    works = []\n",
        "    for it in items:\n",
        "        title = it.get(\"title\", [\"\"])[0]\n",
        "        tcr = it.get(\"type\", \"\")\n",
        "        if tcr not in [\"journal-article\", \"book\"]:\n",
        "            continue\n",
        "        wf = \"article\" if tcr==\"journal-article\" else \"book\"\n",
        "        authors = []\n",
        "        for a in it.get(\"author\", []):\n",
        "            name = \" \".join(filter(None, [a.get(\"given\",\"\"), a.get(\"family\",\"\")]))\n",
        "            authors.append(name)\n",
        "        doi = it.get(\"DOI\")\n",
        "        url_link = f\"https://doi.org/{doi}\" if doi else it.get(\"URL\")\n",
        "        works.append({\n",
        "            \"title\": title,\n",
        "            \"authors\": \", \".join(authors),\n",
        "            \"year\": it.get(\"issued\",{}).get(\"date-parts\",[[None]])[0][0],\n",
        "            \"work_type\": wf,\n",
        "            \"open_access\": False,  # CrossRef usually doesnâ€™t provide OA info\n",
        "            \"pdf_url\": None,\n",
        "            \"url\": url_link,\n",
        "            \"source\": \"CrossRef\",\n",
        "            \"doi\": doi\n",
        "        })\n",
        "    return works\n",
        "\n",
        "def arxiv_author_works(author_name, max_results=50):\n",
        "    client = arxiv.Client()\n",
        "    query = f'au:\"{author_name}\"'\n",
        "    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.SubmittedDate)\n",
        "    works = []\n",
        "    for r in client.results(search):\n",
        "        works.append({\n",
        "            \"title\": r.title,\n",
        "            \"authors\": \", \".join([a.name for a in r.authors]),\n",
        "            \"year\": r.published.year if hasattr(r, \"published\") else None,\n",
        "            \"work_type\": \"article\",\n",
        "            \"open_access\": True,\n",
        "            \"pdf_url\": r.pdf_url,\n",
        "            \"url\": r.entry_id,\n",
        "            \"source\": \"arXiv\",\n",
        "            \"doi\": r.doi\n",
        "        })\n",
        "    return works\n",
        "\n",
        "def aggregate_author_papers(author_name, max_per_source=50):\n",
        "    all_ = []\n",
        "    all_.extend(openalex_author_works(author_name, max_per_source))\n",
        "    all_.extend(crossref_author_works(author_name, max_per_source))\n",
        "    all_.extend(arxiv_author_works(author_name, max_results=50))\n",
        "    df = pd.DataFrame(all_)\n",
        "    if df.empty:\n",
        "        print(\"No works found.\")\n",
        "        return df\n",
        "    df['title_norm'] = df['title'].astype(str).apply(norm)\n",
        "    df = df.drop_duplicates(subset=['title_norm'])\n",
        "    df = df.drop(columns=['title_norm'])\n",
        "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
        "    df = df.sort_values(by=['year'], ascending=False).reset_index(drop=True)\n",
        "    return df[['title','authors','year','work_type','open_access','pdf_url','source','url','doi']]\n",
        "\n",
        "# Run\n",
        "author_name = input(\"Enter professor/author name: \").strip()\n",
        "df_author = aggregate_author_papers(author_name, max_per_source=30)\n",
        "print(f\"\\nFound {len(df_author)} works for author '{author_name}':\\n\")\n",
        "if not df_author.empty:\n",
        "    display(df_author.head(50))\n",
        "else:\n",
        "    print(\"Consider trying a variant of the name.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhAJsT7xmi8N",
        "outputId": "47a31c0b-1695-4f36-8190-92431951d99d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 222, in iter_dependencies\n",
            "    req = Requirement(req_string.strip())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/requirements.py\", line 43, in __init__\n",
            "    self.specifier: SpecifierSet = SpecifierSet(parsed.specifier)\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/specifiers.py\", line 718, in __init__\n",
            "    self._specs = frozenset(map(Specifier, split_specifiers))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/specifiers.py\", line 235, in __init__\n",
            "    match = self._regex.search(spec)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1527, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.12/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1280, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1160, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 999, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 711, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 661, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 124, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 733, in __init__\n",
            "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 423, in _extract_from_extended_frame_gen\n",
            "    fnames.add(filename)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Enter professor/author name: \n",
            "No works found.\n",
            "\n",
            "Found 0 works for author '':\n",
            "\n",
            "Consider trying a variant of the name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests transformers sentencepiece PyMuPDF tqdm --quiet"
      ],
      "metadata": {
        "id": "yCX-lEKOtUZ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}